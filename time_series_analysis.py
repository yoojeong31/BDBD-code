# -*- coding: utf-8 -*-
"""Time series analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eTKjNCwHA_47JucwRIkJoKZowmnIUYxp

**코드**
"""

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""## 특성중요도 찾기 - XGBRegressor"""

df = pd.read_excel('/content/drive/MyDrive/한양여대/캡스톤 데이터 분석/최종_빈도+소비_분석준비_0928.xlsx')
df = df.drop('Unnamed: 0', axis=1)

X = df[['C1',	'C2',	'C3',	'C4',	'C5',	'C6',	'C7',	'M1',	'M2',	'M3',	'M4',	'M5',	'M6',	'M7']]
y = df['expenditure_tour']

# Z-점수 표준화 - 독립변수만 진행(y는 안함)
scaler = StandardScaler()  # 변수명을 scaler로 수정
X_standardized = scaler.fit_transform(X)
X_standardized_df = pd.DataFrame(X_standardized, columns=X.columns)

# 데이터 길이 확인
n = len(X_standardized_df)

# 80%까지를 훈련 데이터로 사용
train_size = int(n * 0.8)

# 시간 순서대로 데이터 분할
X_train = X_standardized_df.iloc[:train_size]
X_test = X_standardized_df.iloc[train_size:]

y_train = y.iloc[:train_size]
y_test = y.iloc[train_size:]

# 필요한 라이브러리 임포트
from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error
import numpy as np

# XGBRegressor 모델 정의
xgb_reg = XGBRegressor()

# 하이퍼파라미터 그리드 설정
param_grid = {
    'n_estimators': [100, 200, 300],         # 트리 개수
    'max_depth': [3, 5, 7],                  # 트리 깊이
    'learning_rate': [0.01, 0.1, 0.2],       # 학습률
    'subsample': [0.6, 0.8, 1.0],            # 각 트리에 사용할 데이터 비율
    'colsample_bytree': [0.6, 0.8, 1.0],     # 각 트리에서 사용할 피처 비율
    'gamma': [0, 0.1, 0.3]                   # 리프 노드 추가 분할 기준
}

# 그리드 서치 정의 (10-fold 교차 검증 사용)
grid_search = GridSearchCV(xgb_reg, param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)

# 모델 학습
grid_search.fit(X_train, y_train)

# 최적의 하이퍼파라미터와 성능 출력
print("Best Hyperparameters:", grid_search.best_params_)
print("Best RMSE from Grid Search:", np.sqrt(-grid_search.best_score_))

# 최적의 모델로 예측 수행
best_xgb_reg = grid_search.best_estimator_
y_pred_train = best_xgb_reg.predict(X_train)
y_pred_test = best_xgb_reg.predict(X_test)

# 성능 평가: MSE 및 RMSE 계산
mse_train = mean_squared_error(y_train, y_pred_train)
rmse_train = np.sqrt(mse_train)
mse_test = mean_squared_error(y_test, y_pred_test)
rmse_test = np.sqrt(mse_test)

# 결과 출력
print("XGBRegressor RMSE - train:", rmse_train)
print("XGBRegressor RMSE - test:", rmse_test)

# XGBRegressor로 특성중요도 찾기
# 특성 중요도 계산 (기본은 'weight', 빈도를 기준으로 기여도 계산)
importance = best_xgb_reg.feature_importances_

# 중요도와 각 변수 이름을 함께 보기 위해 DataFrame 생성
feature_importance_df = pd.DataFrame({
    'Feature': X_train.columns[:X_train.shape[1]],  # 독립변수 이름
    'Importance': importance
})

# 기여도가 큰 순으로 정렬
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
print(feature_importance_df)

# 중요도 시각화
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='blue')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importance in XGBRegressor')
plt.gca().invert_yaxis()
plt.show()

# 상위 5개로 Prophet - 외생변수 추가에 넣기

"""## Prophet에 외부변수까지 추가 - 특성중요도 반영

"""

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

import pandas as pd
import numpy as np
from prophet import Prophet
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import ParameterGrid

# 데이터 불러오기 (ds: 날짜, y: 종속변수)
df3 = pd.read_excel('/content/drive/MyDrive/한양여대/캡스톤 데이터 분석/최종_빈도+소비_분석준비_0928.xlsx')
df3 = df3.drop('Unnamed: 0', axis=1)
df3 = df3.rename(columns={'일자': 'ds', 'expenditure_tour': 'y'})

# 날짜 확인
print(df3['ds'].unique())
# 결측치 확인
print(df3.isnull().sum())

# 특성 중요도 반영. 반영안하려면 이 줄 삭제
df3 = df3[['ds', 'C5', 'M1', 'M3', 'M4', 'M5', 'y']]

# 날짜 datetime으로 변경
df3['ds'] = pd.to_datetime(df3['ds'].astype(str), format='%Y%m%d')
df3.head()


# 훈련/검증 데이터셋 생성.
# 데이터 길이 확인
n = len(df3)
# 70%까지를 훈련 데이터로 사용
train_size = int(n * 0.7)
train_size
# 시간 순서대로 데이터 분할
df3_train = df3.iloc[:train_size]
df3_test = df3.iloc[train_size:]

df3_test.head()

# 파라미터 탐색을 위한 그리드 서치
param_grid = {
    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],
    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0]
}

best_params = None
best_rmse = float('inf')

# 최적 파라미터 탐색
for params in ParameterGrid(param_grid):
    model2 = Prophet(**params)

    # 외부 변수 추가
    for i in [5]:
      model2.add_regressor(f'C{i}')
      print(f'C{i}')
    for i in [1, 3, 4, 5]:
      print(f'M{i}')
      model2.add_regressor(f'M{i}')

    model2.fit(df3_train)

    # 예측 데이터 생성
    future = pd.DataFrame({'ds': df3_test['ds']})
    print('future: ', future)

    for i in [5]:
      future[f'C{i}'] = df3_test[f'C{i}'].values    # 테스트 데이터의 외부 변수 추가
    for i in [1, 3, 4, 5]:
      future[f'M{i}'] = df3_test[f'M{i}'].values    # 테스트 데이터의 외부 변수 추가


    # 예측 수행
    forecast = model2.predict(future)

    # RMSE 계산
    actual = df3_test['y'].values
    predicted = forecast[-len(df3_test):]['yhat'].values
    rmse = np.sqrt(mean_squared_error(actual, predicted))

    # 최적 파라미터 업데이트
    if rmse < best_rmse:
        best_rmse = rmse
        best_params = params

print("Best Parameters:", best_params)
print("Best RMSE:", best_rmse)

# 최적 모델 재학습 및 예측
best_model = Prophet(**best_params)

# 외부 변수 추가
for i in [5]:
  best_model.add_regressor(f'C{i}')
for i in [1, 3, 4, 5]:
  best_model.add_regressor(f'M{i}')

best_model.fit(df3_train)

# 미래 데이터프레임 생성
future_best = pd.DataFrame({'ds': df3_test['ds']})  # 테스트 데이터의 날짜 사용

for i in [5]:
  future_best[f'C{i}'] = df3[f'C{i}'].iloc[train_size:].values
for i in [1, 3, 4, 5]:
  future_best[f'M{i}'] = df3[f'M{i}'].iloc[train_size:].values

# 예측 수행
forecast_best = best_model.predict(future_best)

# RMSE 계산
actual = df3_test['y'].values
predicted = forecast_best['yhat'].values
rmse = np.sqrt(mean_squared_error(actual, predicted))
print("Best Model RMSE:", rmse)

# 예측값 vs 실제값 비교

end = pd.DataFrame({'Predicted' : predicted, 'Actual' : actual})
end.to_excel('/content/drive/MyDrive/한양여대/캡스톤 데이터 분석/Prophet_res.xlsx')

import matplotlib.pyplot as plt

# 예측값과 실제값 비교 시각화 (테스트 데이터만)
plt.figure(figsize=(14, 7))

# 테스트 데이터의 실제값
plt.plot(df3_test['ds'], df3_test['y'], label='Actual', color='blue', linewidth=2)

# 예측값
plt.plot(forecast_best['ds'], forecast_best['yhat'], label='Predicted', color='orange', linestyle='-', linewidth=2)

# 예측값의 불확실성 범위
plt.fill_between(forecast_best['ds'], forecast_best['yhat_lower'], forecast_best['yhat_upper'], color='gray', alpha=0.2, label='Uncertainty Interval')

# 훈련/검증 데이터 분할 선
plt.axvline(x=df3['ds'].iloc[train_size - 1], color='red', linestyle='--', label='Train/Test Split')

plt.legend()
plt.xlabel('Date')
plt.ylabel('Value')
plt.title('Actual vs Predicted Values on Test Data with Prophet')
plt.grid()
plt.show()

"""## Prophet - 외생변수 추가 및 특성중요도 반영 결과:
Best Model RMSE: 3030355146.3224607

--> rmse 30억 정도라 제일 성능 좋은 듯???
"""